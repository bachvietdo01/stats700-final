---
title: "STATS 700 Final Project: Mixture Model on Source Detection Problem"
author: "Bach Viet Do"
date: "`r format(Sys.time(), '%d %B, %Y')`"
geometry: "left=2.5cm,right=2.5cm,top=1.5cm,bottom=1.5cm"
output:
  md_document:
    toc: true
    variant: markdown
    preserve_yaml: true
---

# Prepare & plot Chandra dataset

```{r}
# libraries
require(ggplot2)
require(mvtnorm)
require(CholWishart)
```

```{r message=FALSE, results='hide'}
# source the codes
Rcpp::sourceCpp('utils/helpers.cpp')
source('utils/visualisation.R')
source('utils/helpers.R')

load('data/chandrasubset.RData')
rm(list=ls()[! ls() %in% c("spatial")])
data = list(X = spatial)
```

```{r}
# plot data
data <- list(X = spatial[1:1000,])
ggplot() + geom_point(data = data.frame(x = data$X[,1], y = data$X[,2]), aes(x, y)) 
```

# Mixture of Finite Gaussian Mixture Model and Uniform Background

## Inference Algorithm 1: EM algorithm


```{r}
# source the codes
source('em/_em_component.R')
source('em/_em_mixture.R')
source('em/_em_mmsignal.R')
source('utils/helpers.R')
source('utils/visualisation.R')
```

```{r results = "hide", cache=TRUE}
# prepare to run EM
X = as.matrix(data$X)
Ks = 6

# intialize the em paramters
s = rep(1, nrow(X))
z = kmeans(x = X, Ks + 1)$cluster
m_init = matrix(rep(apply(X, 2, min), Ks), nrow = dim(X)[2] )
m_init[, 1] = c(4042, 4155)
m_init[, 2] = c(4045, 4180)
m_init[, 3] = c(4055, 4140)
m_init[, 4] = c(4055, 4150)
m_init[, 5] = c(4055, 4175)
m_init[, 6] = c(4070, 4180)


gem_init_pars = get_EMNormComponent_example_init_pars(2)
gem_init_pars$m_init = m_init

chandra = EMMixSigAndBg(Ks = Ks, D = 2, X = X, s = s, z = z,
               sig_componentClass = EMNormComponent, sig_init_pars = gem_init_pars)
  
# run EM
niters = 20

loglik <- rep(0, niters)
for(i in 1:niters) {
  if (i == 1 || i %% 5 == 0 ) {
    print(paste(c('iter:', i)))
  }
    
  chandra$em_update()
  loglik[i] <- chandra$get_loglik()
}
```

```{r}
# plot out the inference result
print(plot_2D_MM_signal(chandra))
print(plot_em_loglik(loglik))
```


## Inference Algorithm 2: Gibbs Sampler

```{r}
source('finite_gibbs/_component.R')
source('finite_gibbs/_mixture.R')
source('finite_gibbs/_fmmsignal.R')
source('utils/helpers.R')
source('utils/visualisation.R')
Rcpp::sourceCpp('utils/helpers.cpp')
```

```{r cache=TRUE, results="hide"}
load('data/em_init.RData')

# prepare to run Gibbs
set.seed(0)
X = as.matrix(data$X)
Ks = 6
Kb = 1

gmm_init_pars = get_GMVNComponent_example_init_pars(2)
m_init = matrix(rep(apply(X, 2, min), Ks), nrow = dim(X)[2] )
m_init[, 1] = c(4045, 4158)
m_init[, 2] = c(4045, 4185)
m_init[, 3] = c(4055, 4140)
m_init[, 4] = c(4055, 4150)
m_init[, 5] = c(4055, 4175)
m_init[, 6] = c(4070, 4180)

gmm_init_pars$m_init = m_init
gmm_init_pars$S0 = 9 * gmm_init_pars$S0
  
# initialize with em run
bz = rep(0, nrow(X))
s = em_init$s
z = em_init$z

chandra = Mixture(Ks = Ks, Kb = Kb, D = 2, X = X, s = s, sz = z, bz = bz,
               sig_componentClass = GMVNComponent, sig_init_pars = gmm_init_pars)
  
# run Gibbs
niters = 20
for(i in 1:niters) {
  if (i == 1 || i %% 5 == 0 ) {
      print(paste(c('iter:', i)))
      for(k in 1:Ks) {
        print(paste(c('Signal cluster k size:', chandra$signal[[1]]$components[[k]]$N)))
      }
    }
    
  chandra$gibbs()
}
```

```{r}
# plot out the last iteration result
print(plot_2D_GMM_signal(chandra, chandra$signal[[1]]$z))
```

```{r}
# plot posterior
post_samp = sample_post(chandra)
output <- sample_theta(k = 6, post_samp$X, post_samp$z, post_samp$K)
print(hist_rho(post_samp$rho))
print(hist_pi(output$pi))
print(hist_mu(output$mu, data$mu))
```

## Inference Algorithm 3: VI Algorithm

```{r}
source('vb/vi_gmm.R')
source('utils/helpers.R')
source('utils/visualisation.R')
```

```{r results="hide"}
set.seed(0)
K = 6
D = 2

# intialize VI algorithm at random
chandra <- vb_gmm(data$X, K = 6, epsilon_conv = 1e-4,
                  animated = FALSE)
```

```{r}
ggplot(data.frame(it = 1: length(chandra$L), ELBO = chandra$L)) + 
  geom_line(aes(it, ELBO)) + geom_point(aes(it, ELBO))

# visualize cluster at convergence
res = make_visual_obj_from_vb(chandra, data$X)
visualize_result(res, res$X, res$K, res$bg_lower, res$bg_upper)
```

## Inference Algorithm 4: DPM Algorithm

```{r}
Rcpp::sourceCpp('utils/helpers.cpp')
source('infinite_gibbs/_component.R')
source('infinite_gibbs/_dpmixture.R')
source('utils/helpers.R')
source('utils/visualisation.R')
```

```{r cache=TRUE, results="hide"}
load('data/em_init.RData')

# prepare to run Gibbs
X = as.matrix(data$X)
K = 12
s = rep(1, nrow(X))
z = kmeans(x = X, K)$cluster
s = em_init$s
z = em_init$z

m0_init = matrix(0, ncol = 6, nrow = 2)
m0_init[, 1] = c(4045, 4158)
m0_init[, 2] = c(4045, 4185)
m0_init[, 3] = c(4055, 4140)
m0_init[, 4] = c(4055, 4150)
m0_init[, 5] = c(4055, 4175)
m0_init[, 6] = c(4070, 4180)


chandra = DPMixture(K = K, D = 2, X = X, s = s, z = z, m0 = colMeans(X),
                 m0_init = m0_init)

# run MFM Gibbs
niters = 20
K_iters = rep(0, niters)
for(i in 1:niters) {
  chandra$collapsed_gibbs()
  K_iters[i] = chandra$K
}
```

```{r}
# plot out the DPM chandra
print(plot_2D_GMM_IMM(chandra))
```

## Inference Algorithm 5: MFM Algorithm

```{r}
Rcpp::sourceCpp('utils/helpers.cpp')
source('infinite_gibbs/_component.R')
source('infinite_gibbs/_mfmmixture.R')
source('utils/helpers.R')
source('utils/visualisation.R')
```

```{r cache = TRUE,results="hide"}
load('data/em_init.RData')

# prepare to run Gibbs
X = as.matrix(data$X)
K = 20

s = em_init$s
z = em_init$z


m0_init = matrix(0, ncol = 6, nrow = 2)
m0_init[, 1] = c(4045, 4158)
m0_init[, 2] = c(4045, 4185)
m0_init[, 3] = c(4055, 4140)
m0_init[, 4] = c(4055, 4150)
m0_init[, 5] = c(4055, 4175)
m0_init[, 6] = c(4070, 4180)


chandra = MFMMixture(K = K, D = 2, X = X, s = s, z = z, m0 = colMeans(X),
                 m0_init = m0_init)

# run MFM Gibbs
niters = 50
K_iters = rep(0, niters)
for(i in 1:niters) {
  chandra$collapsed_gibbs()
  K_iters[i] = chandra$K
}
```

```{r}
# plot out the MFM chandra
print(plot_2D_GMM_IMM(chandra))
```